{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNsqxTn2O+aFpRBYyuIDzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/USCbiostats/PM520/blob/main/Lab_4_Optimization_PtII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ain't no mountain high enough, or: Optimization Pt II\n",
        "Outline for today:\n",
        "1. Newton's Method & Quasi-Newton Methods\n",
        "2. Poisson Regression Lab\n",
        "3. Automatic differentiation"
      ],
      "metadata": {
        "id": "D7LCHBjOhm0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's Method for Optimization\n",
        "Can we do better, by considering higher-order information (ie geometry) of\n",
        "the function $f$?\n",
        "\n",
        "Let's consider a 2nd-order [Taylor-series approximation](https://en.wikipedia.org/wiki/Taylor_series) to $f$ around $\\beta_t$ as,\n",
        "\n",
        "$$f(\\beta) \\approx f(\\beta_t) + \\nabla f(\\beta_t)^T (\\beta - \\beta_t) + \\frac{1}{2} (\\beta - \\beta_t)^T H(\\beta_t)(\\beta - \\beta_t),$$ where $H(\\beta_t) = \\nabla^2 f(\\beta_t)$ (i.e. the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix) of $f$ at $\\beta_t$). If we minimize this _local_ approximation, we see\n",
        "\n",
        "$\\nabla_\\beta f(\\beta) \\approx \\nabla f(\\beta_t) + H(\\beta_t)(\\beta - \\beta_t) = \\nabla f(\\beta_t) + H(\\beta_t)\\beta - H(\\beta_t)\\beta_t ⇒$\n",
        "$$ H(\\beta_t)\\beta = H(\\beta_t)\\beta_t - \\nabla f(\\beta_t).$$\n",
        "\n",
        "We can recognize that this is a [system of linear equations](https://en.wikipedia.org/wiki/System_of_linear_equations) $A x = b$ where $A = H(\\beta_t)$, $x = \\beta$, and $b = H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)$. The solution is given by, $\\hat{x} = A^{-1}b$, which in this case implies,\n",
        "$$ \\hat{\\beta} = H(\\beta_t)^{-1}\\left(H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)\\right) = \\beta_t - H(\\beta_t)^{-1}\\nabla f(\\beta_t).$$\n",
        "\n",
        "\n",
        "\n",
        "[Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) is only guaranteed to converge _locally_, and can diverge even for _strongly_ [convex functions](https://en.wikipedia.org/wiki/Convex_function) (e.g., $f(\\beta) = \\sqrt{\\beta^2 + 1}$). To address this limitation, we can add a dampening parameter, $\\rho_t$, which gives us our final update form,\n",
        "$$ \\hat{\\beta} = H(\\beta_t)^{-1}(H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)) = \\beta_t - \\rho_t H(\\beta_t)^{-1}\\nabla f(\\beta_t).$$\n",
        "\n",
        "## Quasi-Newton Methods for Optimization\n",
        "What if computing $H(\\beta_t)$ is prohibitive or too costly? Do we need _exact_ second order information to improve on gradient descent's convergence? Given an approximation of $H$, called $B$, i.e. $B(\\beta_t) \\approx H(\\beta_t)$, [_quasi_-Newton methods](https://en.wikipedia.org/wiki/Quasi-Newton_method) optimize for the form\n",
        "$$f(\\beta) \\approx f(\\beta_t) + \\nabla f(\\beta_t)^T (\\beta - \\beta_t) + \\frac{1}{2} (\\beta - \\beta_t)^T B(\\beta_t)(\\beta - \\beta_t),$$ where $B(\\beta_t) \\approx H(\\beta_t)$. Optimizing this statement gives us our update rule,\n",
        "$$ \\hat{\\beta} = \\beta_t - \\rho_t B(\\beta_t)^{-1}\\nabla f(\\beta_t).$$"
      ],
      "metadata": {
        "id": "_b5I2Q37z4_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poisson Regression\n",
        "\n",
        "$$y_i | x_i \\sim \\text{Poi}(\\lambda_i)$$ where $\\lambda_i := \\exp(x_i^T \\beta)$, and $\\text{Poi}(k | \\lambda) := \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$ is the [PMF](https://en.wikipedia.org/wiki/Probability_mass_function) of the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution). Given $\\{(y_i, x_i)\\}_{i=1}^n$, we would like to identify the [maximum likelihood parameter estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) for $\\beta$. In other words, we would to find a value for $\\beta$ such that we maximize the log-likelihood given by,\n",
        "$$\\begin{align*}\n",
        "\\log \\ell(\\beta) &= \\sum_i \\log \\text{Poi}(y_i | \\exp(x_i^T \\beta)) \\\\\n",
        "&= \\sum_i \\log \\left[ \\frac{\\exp(y_i \\cdot x_i^T \\beta) \\exp(-\\exp(x_i^T \\beta))}{y_i!} \\right] \\\\\n",
        "&= \\sum_i \\log \\left[ \\frac{\\exp(y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta))}{y_i!} \\right] \\\\\n",
        "&= \\sum_i \\log \\left[\\exp(y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta))\\right] - \\log(y_i!) \\\\\n",
        "&= \\sum_i \\left[y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta) - \\log(y_i!)\\right] \\\\\n",
        "&= y^T X\\beta - \\exp(X\\beta)^T 1_n - O(1) \\\\\n",
        "&= y^T X\\beta - \\lambda^T 1_n - O(1),\n",
        "\\end{align*}$$\n",
        "where $\\lambda = \\{\\lambda_1, \\dotsc, \\lambda_n\\}.$\n",
        "\n",
        "\n",
        "$$ \\begin{align*}\n",
        "\\nabla_\\beta \\ell &= \\nabla_\\beta \\left[ y^T X\\beta - \\lambda^T 1_n \\right] \\\\\n",
        "&= \\nabla_\\beta [ y^T X\\beta ] - \\nabla_\\beta [\\lambda^T 1_n] \\\\\n",
        "&= \\nabla_\\beta [ y^T X\\beta ] - \\nabla_\\beta [\\exp(X\\beta)^T 1_n] \\\\\n",
        "&= X^T y - X^T \\exp(X\\beta)  \\\\\n",
        "&= X^T y - X^T \\lambda  \\\\\n",
        "&= X^T(y - \\lambda) \\\\\n",
        "\\nabla^2_{\\beta \\beta} \\ell &= \\nabla_{\\beta} X^T(y - \\lambda) \\\\\n",
        "&= \\nabla_{\\beta} \\left[X^T y - X^T \\lambda \\right] \\\\\n",
        "&= - X^T \\nabla_{\\beta}  \\lambda \\\\\n",
        "&= -X^T \\nabla_{\\beta}  \\exp(X\\beta) \\\\\n",
        "&= -X^T \\Lambda X,\n",
        "\\end{align*}$$\n",
        "where $\\Lambda = \\text{diag}(\\lambda)$, i.e. $\\Lambda_{ii} = \\lambda_i$ and $\\Lambda_{ij} = 0$ for $i \\neq j$.\n",
        "\n",
        "To illustrate how $\\nabla_{\\beta}  \\exp(X\\beta) = \\Lambda X$ (i.e. last step in Hessian calculation), recall that the [Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) of a function $f : \\mathbb{R}^n → \\mathbb{R}^m$ is the $m \\times n$ matrix $J$ such that $J_{ij} = \\frac{∂f_i}{∂j}$. In this case we are computing the Jacobian for $\\exp(X\\beta)$, which is $\\mathbb{R}^p → \\mathbb{R}^n$, so our final Jacobian for $\\exp(X\\beta)$ should have shape $n \\times p$. Notice that $J_{i,j} = \\frac{\\partial}{\\partial \\beta_j} \\exp(x_i^T \\beta) = x_{ij}\\exp(x_i^T \\beta)$, thus $J_{i, .} = \\exp(x_i^T \\beta) x_i^T$. Repeating this for each $i$ we have $$∇_\\beta \\exp(X \\beta) = J(\\exp(X \\beta)) = \\begin{bmatrix} J_{1,.} \\\\ ⋮ \\\\ J_{n,.} \\end{bmatrix} =\n",
        "\\begin{bmatrix} \\exp(x_1^T \\beta) x_1^T \\\\ ⋮ \\\\ \\exp(x_n^T \\beta) x_n^T \\end{bmatrix}  =\n",
        "\\begin{bmatrix} \\lambda_1 x_1^T \\\\ ⋮ \\\\ \\lambda_n x_n^T\\end{bmatrix} = \\Lambda X.$$\n",
        "\n",
        "We can fit using Newton's method. =>\n",
        "$$\\begin{align*}\n",
        "\\beta(t+1) &= \\beta(t) - H(\\beta(t))^{-1}\\nabla \\ell(\\beta_t) \\\\\n",
        "&= \\beta(t) + (X^T \\Lambda(t) X)^{-1} X^T (y - \\lambda) ⇒ \\\\\n",
        "&= (X^T \\Lambda(t) X)^{-1} X^T \\Lambda(t) (\\Lambda(t)^{-1}y + X\\beta(t) - 1)\n",
        "\\end{align*}$$\n",
        "where $\\Lambda(t) := \\text{diag}(\\lambda_1, \\dotsc, \\lambda_n)$."
      ],
      "metadata": {
        "id": "crQSiZATzm9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lineax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrxzG7-0r2x_",
        "outputId": "7f5a651f-a1f3-4615-e3ee-826edc7921c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lineax in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: equinox>=0.11.5 in /usr/local/lib/python3.11/dist-packages (from lineax) (0.11.11)\n",
            "Requirement already satisfied: jax>=0.4.26 in /usr/local/lib/python3.11/dist-packages (from lineax) (0.5.0)\n",
            "Requirement already satisfied: jaxtyping>=0.2.20 in /usr/local/lib/python3.11/dist-packages (from lineax) (0.2.37)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from lineax) (4.12.2)\n",
            "Requirement already satisfied: jaxlib<=0.5.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.26->lineax) (0.5.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.26->lineax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.26->lineax) (1.26.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.26->lineax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.26->lineax) (1.13.1)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping>=0.2.20->lineax) (0.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as rdm\n",
        "import jax.scipy.stats as stats\n",
        "\n",
        "import lineax as lx\n",
        "\n",
        "@jax.jit\n",
        "def loglikelihood(beta, y, X):\n",
        "  \"\"\"\n",
        "  Our loglikelihood function for $y_i | x_i ~ \\text{Poi}(\\exp(eta_i))$.\n",
        "\n",
        "  beta: beta\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix as lx.AbstractLinearOperator\n",
        "\n",
        "  returns: sum of the logliklihoods of each sample\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def irwls_fit(beta, y, X, step_size):\n",
        "  \"\"\"\n",
        "  Perform MLE estimation for $\\beta$ under the model\n",
        "     $y_i | x_i ~ \\text{Poi}(\\exp(x_i^T \\beta))$.\n",
        "\n",
        "  beta: beta\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix\n",
        "\n",
        "  returns: updated estimate of $\\beta$\n",
        "  \"\"\"\n",
        "  # compute lambda_i := exp(x_i @ beta)\n",
        "  eta = X.mv(beta)\n",
        "  d_i = jnp.exp(eta)\n",
        "  d_sqrt = jnp.sqrt(d_i)\n",
        "\n",
        "  # compute z_i := Lambda^{1/2}(Lambda^-1 y + X @beta - 1)\n",
        "  z = (y / d_i + eta - 1) * d_sqrt\n",
        "\n",
        "  # X* := Lambda^{1/2} X\n",
        "  # we use linear operators to postpone any computation\n",
        "  X_star = lx.DiagonalLinearOperator(d_sqrt) @ X\n",
        "\n",
        "  # lineax can solve normal equations iteratively as (t(X*) @ (X* @ guess)) - z\n",
        "  solution = lx.linear_solve(X_star, z, solver=lx.NormalCG(atol=1e-4, rtol=1e-3))\n",
        "  beta = solution.value\n",
        "\n",
        "  return beta\n",
        "\n",
        "\n",
        "def poiss_reg(y, X, fit_func, step_size = 1.0, max_iter=100, tol=1e-3):\n",
        "  \"\"\"\n",
        "  Perform MLE estimation for $\\beta$ under the model\n",
        "     $y_i | x_i ~ \\text{Poi}(\\exp(x_i^T \\beta))$.\n",
        "\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix\n",
        "  max_iter: the maximum number of iterations to perform optimization\n",
        "  tol:\n",
        "\n",
        "  returns: updated estimate of $\\beta$\n",
        "  \"\"\"\n",
        "  # intialize eta := X @ beta\n",
        "  n, p = X.shape\n",
        "\n",
        "  # fake bookkeeping\n",
        "  loglike = -100000\n",
        "  delta = 10000\n",
        "\n",
        "  # convert to a linear operator for lineax\n",
        "  X = lx.MatrixLinearOperator(X)\n",
        "\n",
        "  # initialize using OLS estimate and normalizing for downstream stability\n",
        "  sol = lx.linear_solve(X, (y - jnp.mean(y))/2, solver=lx.NormalCG(atol=1e-4, rtol=1e-3))\n",
        "  beta = sol.value\n",
        "  beta = beta / jnp.linalg.norm(beta)\n",
        "\n",
        "  for epoch in range(max_iter):\n",
        "\n",
        "    # fit using our function\n",
        "    beta = fit_func(beta, y, X, step_size)\n",
        "\n",
        "    # evaluate log likelihood\n",
        "    newll = loglikelihood(beta, y, X)\n",
        "\n",
        "    # take delta and check if we can stop\n",
        "    delta = jnp.fabs(newll - loglike)\n",
        "    print(f\"Log likelihood[{epoch}] = {newll}\")\n",
        "    if delta < tol:\n",
        "      break\n",
        "\n",
        "    # replace old value\n",
        "    loglike = newll\n",
        "\n",
        "  return beta"
      ],
      "metadata": {
        "id": "DKK1oqZMztkU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's simulate a poisson regression model with N samples and P variables\n",
        "# we need X (N,P), beta (P,) and y (N,)\n",
        "N = 1000\n",
        "P = 5\n",
        "\n",
        "# initialize PRNG env\n",
        "seed = 0\n",
        "key = rdm.PRNGKey(seed)\n",
        "\n",
        "# TODO: split key for each random call\n",
        "\n",
        "\n",
        "# TODO: compute lambda_i = exp(x_i' \\beta)\n",
        "\n",
        "\n",
        "# TODO: sample y from Poi(lambda_i)\n",
        "\n",
        "\n",
        "# estimate beta using our irwls function\n",
        "# fit_func has signature (eta, y, X, step_size)\n",
        "beta_hat = poiss_reg(y, X, irwls_fit)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "nRai4qWiz1_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68969c7e-1d74-4a6b-d32a-d7e8b26b4d7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = -39143916.0\n",
            "Log likelihood[1] = -14508134.0\n",
            "Log likelihood[2] = -5372775.0\n",
            "Log likelihood[3] = -1977102.625\n",
            "Log likelihood[4] = -711654.75\n",
            "Log likelihood[5] = -239464.78125\n",
            "Log likelihood[6] = -64012.875\n",
            "Log likelihood[7] = -523.58203125\n",
            "Log likelihood[8] = 20885.935546875\n",
            "Log likelihood[9] = 26847.2421875\n",
            "Log likelihood[10] = 27922.48828125\n",
            "Log likelihood[11] = 27996.65625\n",
            "Log likelihood[12] = 27997.24609375\n",
            "Log likelihood[13] = 27997.25\n",
            "Log likelihood[14] = 27997.24609375\n",
            "Log likelihood[15] = 27997.251953125\n",
            "Log likelihood[16] = 27997.248046875\n",
            "Log likelihood[17] = 27997.24609375\n",
            "Log likelihood[18] = 27997.24609375\n",
            "beta = [ 1.2956359   1.3550105  -0.40960556 -0.77188545  0.38094172]\n",
            "hat(beta) = [ 1.2962791   1.3400909  -0.40938488 -0.77928865  0.3834757 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's implement poisson regression using _only_ gradient information to perform inference\n",
        "# and measure how quickly it converges compared with the Newton method\n",
        "def grad_fit(beta, y, X, step_size):\n",
        "  pass\n",
        "\n",
        "# NB: we can transpose a lx.MatrixLinearOperator (say X) as X.transpose()\n",
        "# NB: we compute matrix-vector produces using a lx.MatrixLinearOperator as X.mv(v)\n",
        "step_size = 1e-5\n",
        "beta_hat = poiss_reg(y, X, grad_fit, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "ZalxS2NOOfiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d2096b-35ce-4a62-84a3-456ff6e2b487"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = 18724.921875\n",
            "Log likelihood[1] = 20996.13671875\n",
            "Log likelihood[2] = 22946.0234375\n",
            "Log likelihood[3] = 24516.162109375\n",
            "Log likelihood[4] = 25680.60546875\n",
            "Log likelihood[5] = 26468.087890625\n",
            "Log likelihood[6] = 26960.0546875\n",
            "Log likelihood[7] = 27257.806640625\n",
            "Log likelihood[8] = 27444.361328125\n",
            "Log likelihood[9] = 27570.61328125\n",
            "Log likelihood[10] = 27662.41796875\n",
            "Log likelihood[11] = 27732.294921875\n",
            "Log likelihood[12] = 27786.658203125\n",
            "Log likelihood[13] = 27829.423828125\n",
            "Log likelihood[14] = 27863.21484375\n",
            "Log likelihood[15] = 27890.0390625\n",
            "Log likelihood[16] = 27911.33984375\n",
            "Log likelihood[17] = 27928.25\n",
            "Log likelihood[18] = 27941.796875\n",
            "Log likelihood[19] = 27952.58984375\n",
            "Log likelihood[20] = 27961.2109375\n",
            "Log likelihood[21] = 27968.14453125\n",
            "Log likelihood[22] = 27973.69921875\n",
            "Log likelihood[23] = 27978.1796875\n",
            "Log likelihood[24] = 27981.78515625\n",
            "Log likelihood[25] = 27984.6796875\n",
            "Log likelihood[26] = 27987.052734375\n",
            "Log likelihood[27] = 27988.9296875\n",
            "Log likelihood[28] = 27990.5\n",
            "Log likelihood[29] = 27991.7265625\n",
            "Log likelihood[30] = 27992.73828125\n",
            "Log likelihood[31] = 27993.599609375\n",
            "Log likelihood[32] = 27994.265625\n",
            "Log likelihood[33] = 27994.806640625\n",
            "Log likelihood[34] = 27995.2578125\n",
            "Log likelihood[35] = 27995.60546875\n",
            "Log likelihood[36] = 27995.908203125\n",
            "Log likelihood[37] = 27996.1640625\n",
            "Log likelihood[38] = 27996.3515625\n",
            "Log likelihood[39] = 27996.51953125\n",
            "Log likelihood[40] = 27996.6875\n",
            "Log likelihood[41] = 27996.75\n",
            "Log likelihood[42] = 27996.86328125\n",
            "Log likelihood[43] = 27996.91796875\n",
            "Log likelihood[44] = 27997.015625\n",
            "Log likelihood[45] = 27997.05078125\n",
            "Log likelihood[46] = 27997.09375\n",
            "Log likelihood[47] = 27997.0859375\n",
            "Log likelihood[48] = 27997.125\n",
            "Log likelihood[49] = 27997.15234375\n",
            "Log likelihood[50] = 27997.14453125\n",
            "Log likelihood[51] = 27997.169921875\n",
            "Log likelihood[52] = 27997.20703125\n",
            "Log likelihood[53] = 27997.2421875\n",
            "Log likelihood[54] = 27997.205078125\n",
            "Log likelihood[55] = 27997.22265625\n",
            "Log likelihood[56] = 27997.234375\n",
            "Log likelihood[57] = 27997.25\n",
            "Log likelihood[58] = 27997.216796875\n",
            "Log likelihood[59] = 27997.25\n",
            "Log likelihood[60] = 27997.2578125\n",
            "Log likelihood[61] = 27997.24609375\n",
            "Log likelihood[62] = 27997.26171875\n",
            "Log likelihood[63] = 27997.267578125\n",
            "Log likelihood[64] = 27997.267578125\n",
            "beta = [ 1.2956359   1.3550105  -0.40960556 -0.77188545  0.38094172]\n",
            "hat(beta) = [ 1.2965922   1.3393312  -0.40922275 -0.77982926  0.38304427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic differentiation\n",
        "Chain rules, okay! Notes TBD"
      ],
      "metadata": {
        "id": "WbJ1nlWE0R7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's not worry and use autodiff\n",
        "auto_grad_ll = jax.grad(loglikelihood)\n",
        "\n",
        "def jax_grad_step(beta, y, X, step_size):\n",
        "  pass\n",
        "\n",
        "# NB: we can transpose a lx.MatrixLinearOperator (say X) as X.transpose()\n",
        "# NB: we compute matrix-vector produces using a lx.MatrixLinearOperator as X.mv(v)\n",
        "step_size = 1e-6\n",
        "beta_hat = poiss_reg(y, X, jax_grad_step, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "dSPl_smqUq9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06691a11-25aa-40ed-ea59-c86b2a2d40f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = 16456.615234375\n",
            "Log likelihood[1] = 16712.373046875\n",
            "Log likelihood[2] = 16965.998046875\n",
            "Log likelihood[3] = 17217.419921875\n",
            "Log likelihood[4] = 17466.59765625\n",
            "Log likelihood[5] = 17713.4609375\n",
            "Log likelihood[6] = 17957.978515625\n",
            "Log likelihood[7] = 18200.03125\n",
            "Log likelihood[8] = 18439.634765625\n",
            "Log likelihood[9] = 18676.671875\n",
            "Log likelihood[10] = 18911.099609375\n",
            "Log likelihood[11] = 19142.8671875\n",
            "Log likelihood[12] = 19371.900390625\n",
            "Log likelihood[13] = 19598.134765625\n",
            "Log likelihood[14] = 19821.53515625\n",
            "Log likelihood[15] = 20042.001953125\n",
            "Log likelihood[16] = 20259.4921875\n",
            "Log likelihood[17] = 20473.96484375\n",
            "Log likelihood[18] = 20685.294921875\n",
            "Log likelihood[19] = 20893.521484375\n",
            "Log likelihood[20] = 21098.5\n",
            "Log likelihood[21] = 21300.220703125\n",
            "Log likelihood[22] = 21498.61328125\n",
            "Log likelihood[23] = 21693.6328125\n",
            "Log likelihood[24] = 21885.2109375\n",
            "Log likelihood[25] = 22073.306640625\n",
            "Log likelihood[26] = 22257.884765625\n",
            "Log likelihood[27] = 22438.890625\n",
            "Log likelihood[28] = 22616.251953125\n",
            "Log likelihood[29] = 22790.001953125\n",
            "Log likelihood[30] = 22960.056640625\n",
            "Log likelihood[31] = 23126.361328125\n",
            "Log likelihood[32] = 23288.931640625\n",
            "Log likelihood[33] = 23447.73046875\n",
            "Log likelihood[34] = 23602.712890625\n",
            "Log likelihood[35] = 23753.904296875\n",
            "Log likelihood[36] = 23901.28125\n",
            "Log likelihood[37] = 24044.82421875\n",
            "Log likelihood[38] = 24184.51953125\n",
            "Log likelihood[39] = 24320.388671875\n",
            "Log likelihood[40] = 24452.447265625\n",
            "Log likelihood[41] = 24580.693359375\n",
            "Log likelihood[42] = 24705.13671875\n",
            "Log likelihood[43] = 24825.814453125\n",
            "Log likelihood[44] = 24942.736328125\n",
            "Log likelihood[45] = 25055.95703125\n",
            "Log likelihood[46] = 25165.49609375\n",
            "Log likelihood[47] = 25271.4140625\n",
            "Log likelihood[48] = 25373.7421875\n",
            "Log likelihood[49] = 25472.548828125\n",
            "Log likelihood[50] = 25567.84375\n",
            "Log likelihood[51] = 25659.740234375\n",
            "Log likelihood[52] = 25748.25390625\n",
            "Log likelihood[53] = 25833.48828125\n",
            "Log likelihood[54] = 25915.505859375\n",
            "Log likelihood[55] = 25994.35546875\n",
            "Log likelihood[56] = 26070.154296875\n",
            "Log likelihood[57] = 26142.94921875\n",
            "Log likelihood[58] = 26212.828125\n",
            "Log likelihood[59] = 26279.890625\n",
            "Log likelihood[60] = 26344.18359375\n",
            "Log likelihood[61] = 26405.83984375\n",
            "Log likelihood[62] = 26464.87109375\n",
            "Log likelihood[63] = 26521.44140625\n",
            "Log likelihood[64] = 26575.6015625\n",
            "Log likelihood[65] = 26627.4375\n",
            "Log likelihood[66] = 26677.01953125\n",
            "Log likelihood[67] = 26724.474609375\n",
            "Log likelihood[68] = 26769.845703125\n",
            "Log likelihood[69] = 26813.255859375\n",
            "Log likelihood[70] = 26854.74609375\n",
            "Log likelihood[71] = 26894.41796875\n",
            "Log likelihood[72] = 26932.3515625\n",
            "Log likelihood[73] = 26968.625\n",
            "Log likelihood[74] = 27003.318359375\n",
            "Log likelihood[75] = 27036.46875\n",
            "Log likelihood[76] = 27068.14453125\n",
            "Log likelihood[77] = 27098.48046875\n",
            "Log likelihood[78] = 27127.50390625\n",
            "Log likelihood[79] = 27155.26171875\n",
            "Log likelihood[80] = 27181.828125\n",
            "Log likelihood[81] = 27207.271484375\n",
            "Log likelihood[82] = 27231.662109375\n",
            "Log likelihood[83] = 27254.984375\n",
            "Log likelihood[84] = 27277.34765625\n",
            "Log likelihood[85] = 27298.8125\n",
            "Log likelihood[86] = 27319.376953125\n",
            "Log likelihood[87] = 27339.1171875\n",
            "Log likelihood[88] = 27358.080078125\n",
            "Log likelihood[89] = 27376.318359375\n",
            "Log likelihood[90] = 27393.775390625\n",
            "Log likelihood[91] = 27410.6171875\n",
            "Log likelihood[92] = 27426.80859375\n",
            "Log likelihood[93] = 27442.380859375\n",
            "Log likelihood[94] = 27457.38671875\n",
            "Log likelihood[95] = 27471.84375\n",
            "Log likelihood[96] = 27485.78125\n",
            "Log likelihood[97] = 27499.1953125\n",
            "Log likelihood[98] = 27512.19140625\n",
            "Log likelihood[99] = 27524.69921875\n",
            "Log likelihood[100] = 27536.798828125\n",
            "Log likelihood[101] = 27548.46875\n",
            "Log likelihood[102] = 27559.7890625\n",
            "Log likelihood[103] = 27570.72265625\n",
            "Log likelihood[104] = 27581.32421875\n",
            "Log likelihood[105] = 27591.560546875\n",
            "Log likelihood[106] = 27601.513671875\n",
            "Log likelihood[107] = 27611.1171875\n",
            "Log likelihood[108] = 27620.48046875\n",
            "Log likelihood[109] = 27629.49609375\n",
            "Log likelihood[110] = 27638.26953125\n",
            "Log likelihood[111] = 27646.796875\n",
            "Log likelihood[112] = 27655.09765625\n",
            "Log likelihood[113] = 27663.173828125\n",
            "Log likelihood[114] = 27670.966796875\n",
            "Log likelihood[115] = 27678.56640625\n",
            "Log likelihood[116] = 27685.94921875\n",
            "Log likelihood[117] = 27693.123046875\n",
            "Log likelihood[118] = 27700.140625\n",
            "Log likelihood[119] = 27706.9375\n",
            "Log likelihood[120] = 27713.560546875\n",
            "Log likelihood[121] = 27720.02734375\n",
            "Log likelihood[122] = 27726.302734375\n",
            "Log likelihood[123] = 27732.42578125\n",
            "Log likelihood[124] = 27738.3984375\n",
            "Log likelihood[125] = 27744.22265625\n",
            "Log likelihood[126] = 27749.880859375\n",
            "Log likelihood[127] = 27755.3984375\n",
            "Log likelihood[128] = 27760.8046875\n",
            "Log likelihood[129] = 27766.060546875\n",
            "Log likelihood[130] = 27771.154296875\n",
            "Log likelihood[131] = 27776.1875\n",
            "Log likelihood[132] = 27781.046875\n",
            "Log likelihood[133] = 27785.82421875\n",
            "Log likelihood[134] = 27790.494140625\n",
            "Log likelihood[135] = 27795.0078125\n",
            "Log likelihood[136] = 27799.439453125\n",
            "Log likelihood[137] = 27803.796875\n",
            "Log likelihood[138] = 27808.0\n",
            "Log likelihood[139] = 27812.140625\n",
            "Log likelihood[140] = 27816.15234375\n",
            "Log likelihood[141] = 27820.0859375\n",
            "Log likelihood[142] = 27823.951171875\n",
            "Log likelihood[143] = 27827.701171875\n",
            "Log likelihood[144] = 27831.359375\n",
            "Log likelihood[145] = 27834.958984375\n",
            "Log likelihood[146] = 27838.47265625\n",
            "Log likelihood[147] = 27841.921875\n",
            "Log likelihood[148] = 27845.21875\n",
            "Log likelihood[149] = 27848.482421875\n",
            "Log likelihood[150] = 27851.708984375\n",
            "Log likelihood[151] = 27854.8359375\n",
            "Log likelihood[152] = 27857.86328125\n",
            "Log likelihood[153] = 27860.861328125\n",
            "Log likelihood[154] = 27863.75390625\n",
            "Log likelihood[155] = 27866.634765625\n",
            "Log likelihood[156] = 27869.43359375\n",
            "Log likelihood[157] = 27872.12890625\n",
            "Log likelihood[158] = 27874.798828125\n",
            "Log likelihood[159] = 27877.416015625\n",
            "Log likelihood[160] = 27879.943359375\n",
            "Log likelihood[161] = 27882.435546875\n",
            "Log likelihood[162] = 27884.890625\n",
            "Log likelihood[163] = 27887.26171875\n",
            "Log likelihood[164] = 27889.60546875\n",
            "Log likelihood[165] = 27891.890625\n",
            "Log likelihood[166] = 27894.119140625\n",
            "Log likelihood[167] = 27896.298828125\n",
            "Log likelihood[168] = 27898.42578125\n",
            "Log likelihood[169] = 27900.53515625\n",
            "Log likelihood[170] = 27902.5546875\n",
            "Log likelihood[171] = 27904.54296875\n",
            "Log likelihood[172] = 27906.4921875\n",
            "Log likelihood[173] = 27908.423828125\n",
            "Log likelihood[174] = 27910.275390625\n",
            "Log likelihood[175] = 27912.083984375\n",
            "Log likelihood[176] = 27913.8828125\n",
            "Log likelihood[177] = 27915.640625\n",
            "Log likelihood[178] = 27917.34375\n",
            "Log likelihood[179] = 27919.015625\n",
            "Log likelihood[180] = 27920.66796875\n",
            "Log likelihood[181] = 27922.25390625\n",
            "Log likelihood[182] = 27923.837890625\n",
            "Log likelihood[183] = 27925.3515625\n",
            "Log likelihood[184] = 27926.84375\n",
            "Log likelihood[185] = 27928.328125\n",
            "Log likelihood[186] = 27929.771484375\n",
            "Log likelihood[187] = 27931.171875\n",
            "Log likelihood[188] = 27932.53125\n",
            "Log likelihood[189] = 27933.8984375\n",
            "Log likelihood[190] = 27935.21875\n",
            "Log likelihood[191] = 27936.49609375\n",
            "Log likelihood[192] = 27937.75\n",
            "Log likelihood[193] = 27938.99609375\n",
            "Log likelihood[194] = 27940.2109375\n",
            "Log likelihood[195] = 27941.380859375\n",
            "Log likelihood[196] = 27942.556640625\n",
            "Log likelihood[197] = 27943.677734375\n",
            "Log likelihood[198] = 27944.77734375\n",
            "Log likelihood[199] = 27945.84375\n",
            "Log likelihood[200] = 27946.927734375\n",
            "Log likelihood[201] = 27947.931640625\n",
            "Log likelihood[202] = 27948.9921875\n",
            "Log likelihood[203] = 27949.95703125\n",
            "Log likelihood[204] = 27950.94140625\n",
            "Log likelihood[205] = 27951.890625\n",
            "Log likelihood[206] = 27952.806640625\n",
            "Log likelihood[207] = 27953.736328125\n",
            "Log likelihood[208] = 27954.642578125\n",
            "Log likelihood[209] = 27955.48828125\n",
            "Log likelihood[210] = 27956.369140625\n",
            "Log likelihood[211] = 27957.197265625\n",
            "Log likelihood[212] = 27958.02734375\n",
            "Log likelihood[213] = 27958.81640625\n",
            "Log likelihood[214] = 27959.6015625\n",
            "Log likelihood[215] = 27960.37890625\n",
            "Log likelihood[216] = 27961.15234375\n",
            "Log likelihood[217] = 27961.876953125\n",
            "Log likelihood[218] = 27962.59375\n",
            "Log likelihood[219] = 27963.2890625\n",
            "Log likelihood[220] = 27963.9921875\n",
            "Log likelihood[221] = 27964.640625\n",
            "Log likelihood[222] = 27965.31640625\n",
            "Log likelihood[223] = 27965.951171875\n",
            "Log likelihood[224] = 27966.583984375\n",
            "Log likelihood[225] = 27967.2578125\n",
            "Log likelihood[226] = 27967.8515625\n",
            "Log likelihood[227] = 27968.435546875\n",
            "Log likelihood[228] = 27969.02734375\n",
            "Log likelihood[229] = 27969.583984375\n",
            "Log likelihood[230] = 27970.18359375\n",
            "Log likelihood[231] = 27970.705078125\n",
            "Log likelihood[232] = 27971.244140625\n",
            "Log likelihood[233] = 27971.7578125\n",
            "Log likelihood[234] = 27972.26953125\n",
            "Log likelihood[235] = 27972.77734375\n",
            "Log likelihood[236] = 27973.26953125\n",
            "Log likelihood[237] = 27973.78125\n",
            "Log likelihood[238] = 27974.2421875\n",
            "Log likelihood[239] = 27974.69921875\n",
            "Log likelihood[240] = 27975.15234375\n",
            "Log likelihood[241] = 27975.609375\n",
            "Log likelihood[242] = 27976.048828125\n",
            "Log likelihood[243] = 27976.46875\n",
            "Log likelihood[244] = 27976.892578125\n",
            "Log likelihood[245] = 27977.2890625\n",
            "Log likelihood[246] = 27977.697265625\n",
            "Log likelihood[247] = 27978.09375\n",
            "Log likelihood[248] = 27978.494140625\n",
            "Log likelihood[249] = 27978.837890625\n",
            "Log likelihood[250] = 27979.1953125\n",
            "Log likelihood[251] = 27979.541015625\n",
            "Log likelihood[252] = 27979.921875\n",
            "Log likelihood[253] = 27980.27734375\n",
            "Log likelihood[254] = 27980.59765625\n",
            "Log likelihood[255] = 27980.93359375\n",
            "Log likelihood[256] = 27981.265625\n",
            "Log likelihood[257] = 27981.576171875\n",
            "Log likelihood[258] = 27981.90234375\n",
            "Log likelihood[259] = 27982.201171875\n",
            "Log likelihood[260] = 27982.4921875\n",
            "Log likelihood[261] = 27982.765625\n",
            "Log likelihood[262] = 27983.08203125\n",
            "Log likelihood[263] = 27983.365234375\n",
            "Log likelihood[264] = 27983.62109375\n",
            "Log likelihood[265] = 27983.912109375\n",
            "Log likelihood[266] = 27984.185546875\n",
            "Log likelihood[267] = 27984.4609375\n",
            "Log likelihood[268] = 27984.6875\n",
            "Log likelihood[269] = 27984.921875\n",
            "Log likelihood[270] = 27985.1875\n",
            "Log likelihood[271] = 27985.40625\n",
            "Log likelihood[272] = 27985.66015625\n",
            "Log likelihood[273] = 27985.880859375\n",
            "Log likelihood[274] = 27986.12890625\n",
            "Log likelihood[275] = 27986.349609375\n",
            "Log likelihood[276] = 27986.54296875\n",
            "Log likelihood[277] = 27986.78125\n",
            "Log likelihood[278] = 27986.94921875\n",
            "Log likelihood[279] = 27987.142578125\n",
            "Log likelihood[280] = 27987.3671875\n",
            "Log likelihood[281] = 27987.5546875\n",
            "Log likelihood[282] = 27987.765625\n",
            "Log likelihood[283] = 27987.955078125\n",
            "Log likelihood[284] = 27988.130859375\n",
            "Log likelihood[285] = 27988.3046875\n",
            "Log likelihood[286] = 27988.49609375\n",
            "Log likelihood[287] = 27988.6484375\n",
            "Log likelihood[288] = 27988.826171875\n",
            "Log likelihood[289] = 27988.978515625\n",
            "Log likelihood[290] = 27989.126953125\n",
            "Log likelihood[291] = 27989.31640625\n",
            "Log likelihood[292] = 27989.4140625\n",
            "Log likelihood[293] = 27989.59375\n",
            "Log likelihood[294] = 27989.7421875\n",
            "Log likelihood[295] = 27989.890625\n",
            "Log likelihood[296] = 27990.083984375\n",
            "Log likelihood[297] = 27990.208984375\n",
            "Log likelihood[298] = 27990.3203125\n",
            "Log likelihood[299] = 27990.4921875\n",
            "Log likelihood[300] = 27990.6015625\n",
            "Log likelihood[301] = 27990.73046875\n",
            "Log likelihood[302] = 27990.84375\n",
            "Log likelihood[303] = 27990.98046875\n",
            "Log likelihood[304] = 27991.1328125\n",
            "Log likelihood[305] = 27991.25390625\n",
            "Log likelihood[306] = 27991.3671875\n",
            "Log likelihood[307] = 27991.451171875\n",
            "Log likelihood[308] = 27991.5703125\n",
            "Log likelihood[309] = 27991.673828125\n",
            "Log likelihood[310] = 27991.79296875\n",
            "Log likelihood[311] = 27991.921875\n",
            "Log likelihood[312] = 27992.02734375\n",
            "Log likelihood[313] = 27992.11328125\n",
            "Log likelihood[314] = 27992.234375\n",
            "Log likelihood[315] = 27992.298828125\n",
            "Log likelihood[316] = 27992.400390625\n",
            "Log likelihood[317] = 27992.51171875\n",
            "Log likelihood[318] = 27992.57421875\n",
            "Log likelihood[319] = 27992.6796875\n",
            "Log likelihood[320] = 27992.76171875\n",
            "Log likelihood[321] = 27992.86328125\n",
            "Log likelihood[322] = 27992.98046875\n",
            "Log likelihood[323] = 27993.05859375\n",
            "Log likelihood[324] = 27993.109375\n",
            "Log likelihood[325] = 27993.171875\n",
            "Log likelihood[326] = 27993.26953125\n",
            "Log likelihood[327] = 27993.35546875\n",
            "Log likelihood[328] = 27993.40234375\n",
            "Log likelihood[329] = 27993.484375\n",
            "Log likelihood[330] = 27993.55078125\n",
            "Log likelihood[331] = 27993.638671875\n",
            "Log likelihood[332] = 27993.71875\n",
            "Log likelihood[333] = 27993.7734375\n",
            "Log likelihood[334] = 27993.83203125\n",
            "Log likelihood[335] = 27993.896484375\n",
            "Log likelihood[336] = 27993.9921875\n",
            "Log likelihood[337] = 27994.046875\n",
            "Log likelihood[338] = 27994.109375\n",
            "Log likelihood[339] = 27994.162109375\n",
            "Log likelihood[340] = 27994.208984375\n",
            "Log likelihood[341] = 27994.27734375\n",
            "Log likelihood[342] = 27994.322265625\n",
            "Log likelihood[343] = 27994.375\n",
            "Log likelihood[344] = 27994.43359375\n",
            "Log likelihood[345] = 27994.529296875\n",
            "Log likelihood[346] = 27994.55078125\n",
            "Log likelihood[347] = 27994.6015625\n",
            "Log likelihood[348] = 27994.68359375\n",
            "Log likelihood[349] = 27994.71875\n",
            "Log likelihood[350] = 27994.751953125\n",
            "Log likelihood[351] = 27994.78515625\n",
            "Log likelihood[352] = 27994.841796875\n",
            "Log likelihood[353] = 27994.857421875\n",
            "Log likelihood[354] = 27994.921875\n",
            "Log likelihood[355] = 27995.0234375\n",
            "Log likelihood[356] = 27995.072265625\n",
            "Log likelihood[357] = 27995.087890625\n",
            "Log likelihood[358] = 27995.109375\n",
            "Log likelihood[359] = 27995.17578125\n",
            "Log likelihood[360] = 27995.216796875\n",
            "Log likelihood[361] = 27995.21484375\n",
            "Log likelihood[362] = 27995.263671875\n",
            "Log likelihood[363] = 27995.3125\n",
            "Log likelihood[364] = 27995.35546875\n",
            "Log likelihood[365] = 27995.40234375\n",
            "Log likelihood[366] = 27995.408203125\n",
            "Log likelihood[367] = 27995.46875\n",
            "Log likelihood[368] = 27995.494140625\n",
            "Log likelihood[369] = 27995.53515625\n",
            "Log likelihood[370] = 27995.5703125\n",
            "Log likelihood[371] = 27995.59375\n",
            "Log likelihood[372] = 27995.6015625\n",
            "Log likelihood[373] = 27995.658203125\n",
            "Log likelihood[374] = 27995.697265625\n",
            "Log likelihood[375] = 27995.73828125\n",
            "Log likelihood[376] = 27995.759765625\n",
            "Log likelihood[377] = 27995.80078125\n",
            "Log likelihood[378] = 27995.81640625\n",
            "Log likelihood[379] = 27995.84765625\n",
            "Log likelihood[380] = 27995.87890625\n",
            "Log likelihood[381] = 27995.892578125\n",
            "Log likelihood[382] = 27995.900390625\n",
            "Log likelihood[383] = 27995.951171875\n",
            "Log likelihood[384] = 27995.96875\n",
            "Log likelihood[385] = 27996.01171875\n",
            "Log likelihood[386] = 27996.044921875\n",
            "Log likelihood[387] = 27996.0078125\n",
            "Log likelihood[388] = 27996.03515625\n",
            "Log likelihood[389] = 27996.0703125\n",
            "Log likelihood[390] = 27996.078125\n",
            "Log likelihood[391] = 27996.087890625\n",
            "Log likelihood[392] = 27996.146484375\n",
            "Log likelihood[393] = 27996.158203125\n",
            "Log likelihood[394] = 27996.20703125\n",
            "Log likelihood[395] = 27996.21875\n",
            "Log likelihood[396] = 27996.2265625\n",
            "Log likelihood[397] = 27996.2578125\n",
            "Log likelihood[398] = 27996.263671875\n",
            "Log likelihood[399] = 27996.294921875\n",
            "Log likelihood[400] = 27996.27734375\n",
            "Log likelihood[401] = 27996.30078125\n",
            "Log likelihood[402] = 27996.32421875\n",
            "Log likelihood[403] = 27996.357421875\n",
            "Log likelihood[404] = 27996.37109375\n",
            "Log likelihood[405] = 27996.38671875\n",
            "Log likelihood[406] = 27996.4375\n",
            "Log likelihood[407] = 27996.45703125\n",
            "Log likelihood[408] = 27996.453125\n",
            "Log likelihood[409] = 27996.44921875\n",
            "Log likelihood[410] = 27996.48046875\n",
            "Log likelihood[411] = 27996.4921875\n",
            "Log likelihood[412] = 27996.478515625\n",
            "Log likelihood[413] = 27996.5078125\n",
            "Log likelihood[414] = 27996.52734375\n",
            "Log likelihood[415] = 27996.548828125\n",
            "Log likelihood[416] = 27996.5390625\n",
            "Log likelihood[417] = 27996.580078125\n",
            "Log likelihood[418] = 27996.580078125\n",
            "beta = [ 1.2956359   1.3550105  -0.40960556 -0.77188545  0.38094172]\n",
            "hat(beta) = [ 1.2987918   1.3307527  -0.4092786  -0.7854986   0.38030887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.scipy.linalg as spla\n",
        "\n",
        "# Great! But can we use 2nd order information?\n",
        "auto_hess_ll = jax.hessian(loglikelihood)\n",
        "\n",
        "def jax_newton_step(beta, y, X, step_size):\n",
        "  pass\n",
        "\n",
        "step_size = 1.\n",
        "beta_hat = poiss_reg(y, X, jax_newton_step, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "qtbqZkAlWPuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}