{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNck0+J83npQlx8MbWfcerg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/USCbiostats/PM520/blob/main/Lab_7_Intro_Bayesian_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Don't Stop Believin', or: Intro to Bayesian Inference\n",
        "$\\newcommand{\\data}{\\text{Data}}$\n",
        "$\\newcommand{\\E}{\\mathbb{E}}$\n",
        "So far, we've focused primarily on [likelihood](https://en.wikipedia.org/wiki/Likelihood_function)-based inference using [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation), or MLE. Recall that MLE roughly seeks $$\\hat{\\theta}_{MLE} := \\arg \\max_{\\theta} \\ell(\\theta | \\data) = \\arg \\min_{\\theta} \\log \\Pr(\\data | \\theta),$$\n",
        "where $\\ell(\\theta | \\data)$ is a log-likelihood function and $\\theta$ are the parameters of interest. This procedure operationally reflects identifying a value of $\\theta$ such that our observed $\\data$ is most likely.\n",
        "\n",
        "In contrast to this regime, [_Bayesian_ inference](https://en.wikipedia.org/wiki/Bayesian_inference) operationally reflects updating our _beliefs_ about $\\theta$ conditioned on having observed $\\data$. The celebrated [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) states,\n",
        "$$\\Pr(\\theta | \\data) = \\frac{\\Pr(\\data | \\theta) \\Pr(\\theta)}{\\Pr(\\data)},$$\n",
        "where $\\Pr(\\theta | \\data)$ is the [_posterior_ probability](https://en.wikipedia.org/wiki/Posterior_probability) for $\\theta$ and reflects our uncertainty in the values that $\\theta$ may take on, $\\Pr(\\data | \\theta)$ is our likelihood, $\\Pr(\\theta)$ is a [_prior_ probability](https://en.wikipedia.org/wiki/Prior_probability) (or _prior_) over $\\theta$ and $\\Pr(\\data)$ is a [_marginal_ probability/likelihood](https://en.wikipedia.org/wiki/Marginal_likelihood) of the data. In the case that $\\theta$ is continuous we have,\n",
        "$$ \\Pr(\\data) \\int \\Pr(\\data | \\theta') \\Pr(\\theta')d\\theta'$$ and in the case\n",
        "that $\\theta$ is discrete we have,\n",
        "$$\\Pr(\\data) = \\sum_{\\theta'} \\Pr(\\data | \\theta') \\Pr(\\theta').$$\n",
        "\n",
        "\n",
        "\n",
        "## Example\n",
        "TBD"
      ],
      "metadata": {
        "id": "QYQci7HuXVeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Estimators\n",
        "When performing Bayesian inference, we often seek to identify the posterior expectation of $\\theta$ which is given by, $$\\E[\\theta | \\data] = \\int \\theta \\Pr(\\theta | \\data) d\\theta$$ (or analogously using summation for discrete $\\theta)$. Importantly, this is a _conditional_ expectation! This is the expected value (or mean) given our observations $\\data$, which is different from the unconditional, or _prior_ expectation $\\E[\\theta] = \\int \\theta \\Pr(\\theta) d \\theta$. This further reflects how our beliefs about the values $\n",
        "\\theta$ may take on change after having observed $\\data$.\n",
        "\n",
        "As currently stated, it is somewhat unclear why we should select $\\hat{\\theta} = \\E[\\theta | \\data]$ as our [estimator](https://en.wikipedia.org/wiki/Bayes_estimator), but we can reformulate this procedure under a _risk_ framework. Let's define the risk of some estimate $\\hat{\\theta}$ as, $$\\E[L(\\theta, \\hat{\\theta}) | \\data]$$ where $L(\\theta, \\hat{\\theta})$ is a [loss function](https://en.wikipedia.org/wiki/Loss_function) that reflects some notion of _distance_ between some putative \"true\" value $\\theta$ and our estimate $\\hat{\\theta}$. If we select a quadratic loss, we have\n",
        "$$\\E[(\\theta - \\hat{\\theta})^2 | \\data]$$, which is the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error), or MSE. With a bit of algebra, it's clear that our estimator $\\hat{\\theta}$ should result in, $\\hat{\\theta} = \\E[\\theta | \\data]$, which is the posterior expectation!\n",
        "\n",
        "An alternative approach may be to seek the values $\\theta$ which maximize our posterior $\\Pr(\\theta | \\data)$, hence its name [maximum a-posteriori](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation), or MAP for short. Its definition is given by, $$\\hat{\\theta}_{MAP} := \\arg \\max_\\theta \\log \\Pr(\\theta | \\data).$$ While this can be a valid approach in some sense, it seeks a value that is most-probable given our observations $\\data$, or the distributional [mode](https://en.wikipedia.org/wiki/Mode_(statistics)), which not be a good reflection of the inherent uncertainty around its value."
      ],
      "metadata": {
        "id": "1mySqE7zlGsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "TBD"
      ],
      "metadata": {
        "id": "gHv3JnpunjIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyrlQR66XIU_"
      },
      "outputs": [],
      "source": [
        "# code for above example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conjugate Priors and Exponential Families\n",
        "TBD"
      ],
      "metadata": {
        "id": "3g6cTU8wnnqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for above using our ExpFam classes"
      ],
      "metadata": {
        "id": "q00LkeRdnqs_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}