{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/USCbiostats/PM520/blob/main/Lab_3_Optimization_PtI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1bg914lpQpN"
   },
   "source": [
    "# Move on Up, or: Maximum likelihood Estimation & Optimization Pt I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro-mle-optimization"
   },
   "source": [
    "Before we write optimization code, it helps to be explicit about the statistical target. In this notebook, we assume\n",
    "$$\n",
    "x_1,\\dots,x_n \\overset{\\mathrm{iid}}{\\sim} p(\\cdot \\mid \\theta), \\quad \\theta \\in \\Theta,\n",
    "$$\n",
    "and we observe $x_{1:n} = (x_1,\\dots,x_n)$. The core inferential question is: which $\\theta$ makes the observed data most plausible under this model?\n",
    "\n",
    "That leads to [maximum likelihood estimation (MLE)](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation):\n",
    "$$\n",
    "\\hat{\\theta}_{\\mathrm{MLE}} \\in \\arg\\max_{\\theta \\in \\Theta} \\; \\ell(\\theta \\mid x_{1:n}),\n",
    "\\quad\n",
    "L(\\theta \\mid x_{1:n}) = \\prod_{i=1}^n p(x_i \\mid \\theta),\n",
    "\\quad\n",
    "\\ell(\\theta \\mid x_{1:n}) = \\log L(\\theta \\mid x_{1:n}) = \\sum_{i=1}^n \\log p(x_i \\mid \\theta).\n",
    "$$\n",
    "Equivalent optimization form:\n",
    "$$\n",
    "\\hat{\\theta}_{\\mathrm{MLE}} \\in \\arg\\min_{\\theta \\in \\Theta} \\; f(\\theta),\n",
    "\\quad f(\\theta) = -\\ell(\\theta \\mid x_{1:n}).\n",
    "$$\n",
    "\n",
    "Sometimes this minimizer has a closed form (for example, Normal mean/variance and Exponential rate). In many important models (for example, [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)), we do not get a closed form and must use iterative numerical optimization such as [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent). So this lab connects statistical definitions to concrete computational methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAK5-ADoNq_I"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbaYn27uwi28"
   },
   "source": [
    "## MLE for iid Normal data\n",
    "Let $x_1, \\dotsc, x_n \\overset{\\mathrm{iid}}{\\sim} N(\\mu, \\sigma^2)$ where $N(\\mu, \\sigma^2)$ refers to the [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) with mean parameter $\\mu$ and variance parameter $\\sigma^2$. The likelihood of our data is given by,\n",
    "$$\\begin{align*}\n",
    "L(\\mu, \\sigma^2 | x_1, \\dots, x_n) &=\n",
    "  \\prod_{i=1}^n N(x_i | \\mu, \\sigma^2) \\\\\n",
    "  &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right)\\\\\n",
    "  &= \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus, our _log_-likelihood is given by,\n",
    "$$\\begin{align*}\n",
    "\\ell(\\mu, \\sigma^2 | x_1, \\dots, x_n) &=\n",
    "  \\log \\left[\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\right)\\right]\\\\\n",
    "  &= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWoIiwnVwn6O"
   },
   "outputs": [],
   "source": [
    "def norm_rv(key, n: int, mu: float, sigma_sq: float):\n",
    "  \"\"\"\n",
    "  Samples $n$ observations from $x_i \\sim N(\\mu, \\sigma^2)$\n",
    "\n",
    "  n: the number of observations\n",
    "  mu: the mean parameter\n",
    "  sigma_sq: the variance parameter\n",
    "\n",
    "  returns: x, Array of observations\n",
    "  \"\"\"\n",
    "  x = mu + jnp.sqrt(sigma_sq) * rdm.normal(key, shape=(n,))\n",
    "  return x\n",
    "\n",
    "\n",
    "def norm_mle(x):\n",
    "  \"\"\"\n",
    "  Computes $\\hat{\\mu}_{MLE}$ and $\\hat{\\sigma^2}_{MLE}$.\n",
    "\n",
    "  x: Array of observations\n",
    "\n",
    "  returns: Tuple of $\\hat{\\mu}_{MLE}$ and $\\hat{\\sigma^2}_{MLE}$.\n",
    "  \"\"\"\n",
    "  mu_hat = None\n",
    "  ssq_hat = None\n",
    "\n",
    "  return mu_hat, ssq_hat\n",
    "\n",
    "seed = 0\n",
    "key = rdm.PRNGKey(seed)\n",
    "key, x_key = rdm.split(key)\n",
    "\n",
    "N = 500\n",
    "\n",
    "mu = 58.\n",
    "sigma_sq = 100.\n",
    "x = norm_rv(x_key, N, mu, sigma_sq)\n",
    "#print(f\"x = {x}\")\n",
    "mu_hat, ssq_hat = norm_mle(x)\n",
    "print(f\"MLE[\\mu, \\sigma^2] = {mu_hat}, {ssq_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Z8awgX6GXXv"
   },
   "outputs": [],
   "source": [
    "def sq_diff(param, estimate):\n",
    "  return (param - estimate) ** 2\n",
    "\n",
    "mu = 58.\n",
    "sigma_sq = 100.\n",
    "for N in [50, 100, 1000, 10000]:\n",
    "  key, x_key = rdm.split(key)\n",
    "  # generate N observations\n",
    "  x_n = norm_rv(x_key, N, mu, sigma_sq)\n",
    "  # estimate mu, and sigma_sq\n",
    "  mu_hat, ssq_hat = norm_mle(x_n)\n",
    "  # compute the sq-diff for both and report\n",
    "  mu_err = sq_diff(mu, mu_hat)\n",
    "  ssq_err = sq_diff(sigma_sq, ssq_hat)\n",
    "  print(f\"MSE[{N} | mu, sigma^2] = {mu_err}, {ssq_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTHf96slw__S"
   },
   "source": [
    "## MLE for iid Exponential data\n",
    "Let $x_1, \\dotsc, x_n \\overset{\\mathrm{iid}}{\\sim} Exp(\\lambda)$ where $Exp(\\lambda)$ refers to the [Exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) with rate parameter $\\lambda$. The likelihood of our data is given by,\n",
    "$$\\begin{align*}\n",
    "L(\\lambda | x_1, \\dots, x_n) &=\n",
    "  \\prod_{i=1}^n Exp(x_i | \\lambda) \\\\\n",
    "  &= \\prod_{i=1}^n \\lambda \\exp(-\\lambda x_i).\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus, the _log_-likelihood is\n",
    "$$\\begin{align*}\n",
    "\\ell(\\lambda | x_1, \\dots, x_n)\n",
    "&= \\log L(\\lambda | x_1, \\dots, x_n) \\\\\n",
    "&= n\\log\\lambda - \\lambda \\sum_{i=1}^n x_i.\n",
    "\\end{align*}\n",
    "$$\n",
    "Differentiating and setting to zero gives\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\lambda}\\ell(\\lambda | x_1, \\dots, x_n) = \\frac{n}{\\lambda} - \\sum_{i=1}^n x_i = 0\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\hat{\\lambda}_{\\mathrm{MLE}} = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\bar{x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3kQz53WA8YS"
   },
   "outputs": [],
   "source": [
    "def exp_rv(key, n: int, rate: float):\n",
    "  \"\"\"\n",
    "  Samples $n$ observations from $x_i \\sim Exp(\\lambda)$\n",
    "\n",
    "  n: the number of observations\n",
    "  rate: the $\\lambda$ parameter\n",
    "\n",
    "  returns: x, Array of observations\n",
    "  \"\"\"\n",
    "  mean = 1 / rate\n",
    "  x = mean * rdm.exponential(key, shape=(n,))\n",
    "  return x\n",
    "\n",
    "\n",
    "def exp_mle(x):\n",
    "  \"\"\"\n",
    "  Computes $\\hat{\\lambda}_{MLE}$.\n",
    "\n",
    "  x: Array of observations\n",
    "\n",
    "  returns: $\\hat{\\lambda}_{MLE}$.\n",
    "  \"\"\"\n",
    "  rate_hat = 1. / jnp.mean(x)\n",
    "  return rate_hat\n",
    "\n",
    "key, x_key = rdm.split(key)\n",
    "N = 100\n",
    "rate = 1 / 500.\n",
    "x = exp_rv(x_key, N, rate)\n",
    "#print(f\"x = {x}\")\n",
    "rate_hat = exp_mle(x)\n",
    "print(f\"MLE[\\lambda = {rate}] = {rate_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-amDd6YTLuNI"
   },
   "outputs": [],
   "source": [
    "rate = 1 / 50.\n",
    "for N in [50, 100, 1000, 10000]:\n",
    "  key, x_key = rdm.split(key)\n",
    "  # generate N observations\n",
    "  x_n = exp_rv(x_key, N, rate)\n",
    "  # estimate rate\n",
    "  rate_hat = exp_mle(x_n)\n",
    "  # compute the sq-diff for rate\n",
    "  rate_err = sq_diff(rate, rate_hat)\n",
    "  print(f\"MSE[{N} | \\lambda = {rate}] = {rate_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5mFAyAINs-B"
   },
   "source": [
    "# Gradient descent\n",
    "[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) seeks to iteratively optimize a function $f(\\beta)$ by taking steps in the steepest direction,\n",
    "$$ \\beta_{t+1} = \\beta_t - \\rho_t \\nabla f(\\beta_t),$$\n",
    "where that direction is provided by the [gradient](https://en.wikipedia.org/wiki/Gradient) of $f$.\n",
    "\n",
    "A helpful way to recast gradient descent is that we seek to perform a series of _local_ optimizations,\n",
    "\n",
    "$$\\beta_{t+1} = \\arg\\min_\\beta\\; \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t}\\|\\beta - \\beta_t\\|_2^2.$$\n",
    "\n",
    "To see why these are equivalent, solve the local problem using inner-product notation:\n",
    "$$m(\\beta) = \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t} (\\beta - \\beta_t)^T(\\beta - \\beta_t).$$\n",
    "Now, using calculus again,\n",
    "$$\\begin{align*}\n",
    "\\nabla m(\\beta) &= \\nabla [ \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t} (\\beta - \\beta_t)^T(\\beta - \\beta_t)] \\\\\n",
    "&= \\nabla [\\nabla f(\\beta_t)^T \\beta] + \\frac{1}{2\\rho_t} \\nabla [(\\beta - \\beta_t)^T(\\beta - \\beta_t)] \\\\\n",
    "&= \\nabla f(\\beta_t) + \\frac{1}{\\rho_t}(\\beta - \\beta_t) \\Rightarrow \\\\\n",
    "\\beta_{t+1} &= \\beta_t - \\rho_t \\nabla f(\\beta_t).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Neat! However, notice that the original local objective can be thought of as minimizing the directional derivative, but with a distance penalty, where that distance is defined by the geometry of the parameter space.\n",
    "\n",
    "$$\\beta_{t+1} = \\arg\\min_\\beta\\; \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t}\\mathrm{dist}(\\beta, \\beta_t)^2.$$\n",
    "\n",
    "When the natural geometry is $\\mathbb{R}^p$, then $\\mathrm{dist}(\\beta, \\beta_t)^2 = \\|\\beta - \\beta_t\\|_2^2$. However, there are many geometries that can describe the natural parameter space (for future class ðŸ˜‰)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6LpP-pxNy8y"
   },
   "outputs": [],
   "source": [
    "def sim_linear_reg(key, N, P, r2=0.5):\n",
    "  key, x_key = rdm.split(key)\n",
    "  X = rdm.normal(x_key, shape=(N, P))\n",
    "\n",
    "  key, b_key = rdm.split(key)\n",
    "  beta = rdm.normal(b_key, shape=(P,))\n",
    "\n",
    "  # g = jnp.dot(X, beta)\n",
    "  g = X @ beta\n",
    "  s2g = jnp.var(g)\n",
    "\n",
    "  # back out what s2e is, such that s2g / (s2g + s2e) == h2\n",
    "  s2e = (1 - r2) / r2 * s2g\n",
    "  key, y_key = rdm.split(key)\n",
    "\n",
    "  # add env noise to g, but scale such that var(e) == s2e\n",
    "  y = g + jnp.sqrt(s2e) * rdm.normal(y_key, shape=(N,))\n",
    "  return y, X, beta\n",
    "\n",
    "key, sim_key = rdm.split(key)\n",
    "\n",
    "N = 1000\n",
    "P = 5\n",
    "y, X, beta = sim_linear_reg(sim_key, N, P)\n",
    "\n",
    "def linreg_loss(beta_hat, y, X):\n",
    "  y_hat = X @ beta_hat\n",
    "  return 0.5 * jnp.sum((y - y_hat)**2)\n",
    "\n",
    "def gradient(beta_hat, y, X):\n",
    "  y_hat = X @ beta_hat\n",
    "  return -X.T @ (y - y_hat)\n",
    "\n",
    "step_size = 1 / N\n",
    "diff = 10.\n",
    "last_loss = 1000.\n",
    "idx = 0\n",
    "beta_hat = jnp.zeros((P,))\n",
    "# while delta in loss is large, continue\n",
    "print(f\"true beta = {beta}\")\n",
    "while jnp.fabs(diff) > 1e-3:\n",
    "\n",
    "  # take a step in the direction of the gradient using step_size\n",
    "  beta_hat = beta_hat - step_size * gradient(beta_hat, y, X)\n",
    "\n",
    "  # update our current loss and compute delta\n",
    "  cur_loss = linreg_loss(beta_hat, y, X)\n",
    "  diff = last_loss - cur_loss\n",
    "  last_loss = cur_loss\n",
    "\n",
    "  # wave to the crowd\n",
    "  print(f\"Loss[{idx}]({beta_hat}) = {last_loss}\")\n",
    "  idx += 1\n",
    "\n",
    "# OLS solution\n",
    "beta_hat_ols = jnp.linalg.solve(X.T @ X, X.T @ y)\n",
    "print(f\"ols beta = {beta_hat_ols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyZh3Msjuncp"
   },
   "outputs": [],
   "source": [
    "key, sim_key = rdm.split(key)\n",
    "\n",
    "N = 1000\n",
    "P = 5\n",
    "y, X, beta = sim_linear_reg(sim_key, N, P)\n",
    "\n",
    "step_size = 1 / N\n",
    "diff = 10.\n",
    "last_loss = 1000.\n",
    "idx = 0\n",
    "beta_hat = jnp.zeros((P,))\n",
    "# while delta in loss is large, continue\n",
    "print(\"Using JAX to compute gradient\")\n",
    "print(f\"true beta = {beta}\")\n",
    "while jnp.fabs(diff) > 1e-3:\n",
    "  # take a step in the direction of the gradient using step_size\n",
    "  jax_gradient = jax.grad(linreg_loss)\n",
    "  vandg = jax.value_and_grad(linreg_loss)\n",
    "  cur_loss, g = vandg(beta_hat, y, X)\n",
    "  beta_hat = beta_hat - step_size * g\n",
    "\n",
    "  # update our current loss and compute delta\n",
    "  #cur_loss = linreg_loss(beta_hat, y, X)\n",
    "  diff = last_loss - cur_loss\n",
    "  last_loss = cur_loss\n",
    "\n",
    "  # wave to the crowd\n",
    "  print(f\"Loss[{idx}]({beta_hat}) = {last_loss}\")\n",
    "  idx += 1\n",
    "\n",
    "# OLS solution\n",
    "beta_hat_ols = jnp.linalg.solve(X.T @ X, X.T @ y)\n",
    "print(f\"ols beta = {beta_hat_ols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyIVtqxoTZAv"
   },
   "source": [
    "# Logistic Regression\n",
    "For binary outcomes $y_i \\in \\{0,1\\}$, [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) models\n",
    "$$\n",
    "y_i \\sim \\mathrm{Bernoulli}(\\pi_i), \\quad \\pi_i = \\sigma(x_i^T\\beta), \\quad \\sigma(t)=\\frac{1}{1+e^{-t}},\n",
    "$$\n",
    "where $\\sigma(\\cdot)$ is the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function) and the response follows a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution).\n",
    "\n",
    "Given independent observations, maximizing likelihood is equivalent to minimizing the negative log-likelihood (binary cross-entropy),\n",
    "$$\n",
    "\\mathcal{L}(\\beta) = -\\sum_{i=1}^n \\left[y_i\\log \\pi_i + (1-y_i)\\log(1-\\pi_i)\\right].\n",
    "$$\n",
    "Unlike the Normal and Exponential examples above, this objective does not have a closed-form optimizer for $\\beta$, so we use iterative gradient-based optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXsQ5OQKTcBJ"
   },
   "outputs": [],
   "source": [
    "import jax.nn as nn\n",
    "\n",
    "def sim_logistic_reg(key, N, P, r2=0.5):\n",
    "  key, x_key = rdm.split(key)\n",
    "  X = rdm.normal(x_key, shape=(N, P))\n",
    "\n",
    "  key, b_key = rdm.split(key)\n",
    "  beta = rdm.normal(b_key, shape=(P,))\n",
    "\n",
    "  # g = jnp.dot(X, beta)\n",
    "  g = X @ beta\n",
    "  s2g = jnp.var(g)\n",
    "\n",
    "  # back out what s2e is, such that s2g / (s2g + s2e) == h2\n",
    "  s2e = (1 - r2) / r2 * s2g\n",
    "  key, y_key = rdm.split(key)\n",
    "\n",
    "  # add env noise to g, but scale such that var(e) == s2e\n",
    "  y_latent = g + jnp.sqrt(s2e) * rdm.normal(y_key, shape=(N,))\n",
    "\n",
    "  pi = nn.sigmoid(y_latent)\n",
    "  key, y_key = rdm.split(key)\n",
    "  y = rdm.bernoulli(y_key, pi).astype(float)\n",
    "  return y, X, beta\n",
    "\n",
    "\n",
    "key, sim_key = rdm.split(key)\n",
    "\n",
    "N = 1000\n",
    "P = 5\n",
    "y, X, beta = sim_logistic_reg(sim_key, N, P)\n",
    "\n",
    "def logreg_loss(beta_hat, y, X):\n",
    "  pass\n",
    "\n",
    "\n",
    "step_size = 1 / N\n",
    "diff = 10.\n",
    "last_loss = 1000.\n",
    "idx = 0\n",
    "beta_hat = jnp.ones((P,))\n",
    "# while delta in loss is large, continue\n",
    "print(f\"true beta = {beta}\")\n",
    "while jnp.fabs(diff) > 1e-3:\n",
    "\n",
    "  # take a step in the direction of the gradient using step_size\n",
    "  beta_hat = beta_hat - step_size * jax.grad(logreg_loss)(beta_hat, y, X)\n",
    "\n",
    "  # update our current loss and compute delta\n",
    "  cur_loss = logreg_loss(beta_hat, y, X)\n",
    "  diff = last_loss - cur_loss\n",
    "  last_loss = cur_loss\n",
    "\n",
    "  # wave to the crowd\n",
    "  print(f\"Loss[{idx}]({beta_hat}) = {last_loss}\")\n",
    "  idx += 1\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNs013MfLbVn78gz3w3T08H",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
